{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:18.864357Z",
     "iopub.status.busy": "2025-02-10T14:16:18.864100Z",
     "iopub.status.idle": "2025-02-10T14:16:19.478107Z",
     "shell.execute_reply": "2025-02-10T14:16:19.477060Z",
     "shell.execute_reply.started": "2025-02-10T14:16:18.864333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/medical-chatbot-dataset/validation_data_chatbot.csv\n",
      "/kaggle/input/medical-chatbot-dataset/train_data_chatbot.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:19.479795Z",
     "iopub.status.busy": "2025-02-10T14:16:19.479184Z",
     "iopub.status.idle": "2025-02-10T14:16:23.388977Z",
     "shell.execute_reply": "2025-02-10T14:16:23.387972Z",
     "shell.execute_reply.started": "2025-02-10T14:16:19.479767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/medical-chatbot-dataset\n",
      "Training dataset path: /kaggle/input/medical-chatbot-dataset/train_data_chatbot.csv\n",
      "Validation dataset path: /kaggle/input/medical-chatbot-dataset/validation_data_chatbot.csv\n",
      "Conversion complete.\n",
      "Training data saved to: formatted_training_data.jsonl\n",
      "Validation data saved to: formatted_validation_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "# 🔹 Step 1: Download the dataset using KaggleHub\n",
    "path = kagglehub.dataset_download(\"saifulislamsarfaraz/medical-chatbot-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# 🔹 Step 2: Define the correct file paths\n",
    "train_data = f\"{path}/train_data_chatbot.csv\"\n",
    "val_data = f\"{path}/validation_data_chatbot.csv\"  # Assuming the validation file exists\n",
    "\n",
    "print(\"Training dataset path:\", train_data)\n",
    "print(\"Validation dataset path:\", val_data)\n",
    "\n",
    "# 🔹 Step 3: Function to Convert Dataset to Training Format (Using First 80 Rows)\n",
    "def convert_to_training_format(input_csv, output_file, num_rows=80):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Extract Details from medical report\"\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(input_csv).head(num_rows)  # Take only the first 'num_rows' rows\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for _, row in df.iterrows():\n",
    "            medical_report = f\"Patient asks: {row['short_question']}\"  # Simulating a medical report\n",
    "            extracted_json = json.dumps({\n",
    "                \"answer\": row['short_answer'],\n",
    "                \"tags\": row['tags']\n",
    "            })\n",
    "\n",
    "            training_example = {\n",
    "                \"messages\": [\n",
    "                    system_message,\n",
    "                    {\"role\": \"user\", \"content\": medical_report},\n",
    "                    {\"role\": \"assistant\", \"content\": extracted_json}\n",
    "                ]\n",
    "            }\n",
    "            outfile.write(json.dumps(training_example) + '\\n')\n",
    "\n",
    "# 🔹 Step 4: Convert and Save Both Training and Validation Data (First 80 Rows)\n",
    "train_output_file = \"formatted_training_data.jsonl\"\n",
    "val_output_file = \"formatted_validation_data.jsonl\"\n",
    "\n",
    "convert_to_training_format(train_data, train_output_file, num_rows=80)\n",
    "convert_to_training_format(val_data, val_output_file, num_rows=80)\n",
    "\n",
    "print(\"Conversion complete.\")\n",
    "print(\"Training data saved to:\", train_output_file)\n",
    "print(\"Validation data saved to:\", val_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:23.390486Z",
     "iopub.status.busy": "2025-02-10T14:16:23.390126Z",
     "iopub.status.idle": "2025-02-10T14:16:23.399689Z",
     "shell.execute_reply": "2025-02-10T14:16:23.398553Z",
     "shell.execute_reply.started": "2025-02-10T14:16:23.390451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"Extract Details from medical report\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Patient asks: do i have a yeast infection\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"{\\\"answer\\\": \\\"hi this can be a vaginal fungal infection which is quiet common even in women who are not sexually active this may occur due to poor vaginal hygiene insert vaginal antifungal pessaries for 3 days inside your vagina and take anti histaminic tablets orally maintain good vaginal hygiene thanks\\\", \\\"tags\\\": \\\"['yeast infection']\\\"}\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"Extract Details from medical report\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Patient asks: does your upper backlung area hurt badly with plural effusion  for 3 days now my mid back where my lungs are hurt something awful when i try to move whether it be rolling over in bed or standing up from a chair i have a cough when i lie down so i use my athma inhaler and cough syrup to try to relieve the cough so i can sleep i have been taking ibuprofen for the lung pain but it does not help today i have an icy hot patch on the middle of my back can not say it helps but it does not make things worse\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"{\\\"answer\\\": \\\"if you have a true allergy to sulfa medications then lasix may not be for you it does contain sulfa product if you have difficulty breathing or your airways feel like they are closing off or a rash has developed specifically on the trunk of the body then you should stop taking this medication immediately and consult with your pharmacist and health care provider it is important to differentiate between allergies to medications and side effects if you have experienced intolerable side effects to medications containing sulfa products that does not mean you are allergic work with you local pharmacist and physician to re evaluate this situation and to make sure you are taking medication that is appropriate for you\\\", \\\"tags\\\": \\\"['asthma' 'ibuprofen' 'lung' 'cough' 'inhaler']\\\"}\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"role\": \"system\",\n",
      "            \"content\": \"Extract Details from medical report\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Patient asks: taken off paxil cold turk now on celexa having brain zaps is this from the paxil or celexa staying dzzy  dont seem to have the zaps and dizziness now tll after i take the celexa in the morning time insomnia and light headed just dont know if the celexa is causing a allergic reaction or if its the paxil i was on for a year cant tell since i was on one and put on another one over night can you help and should i cntinue takeing the celexa if it is doing this\"\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"{\\\"answer\\\": \\\"if overdose is suspected contact a poison control center or emergency room immediately us residents can call the us national poison hotline at 1 800 222 1222 canada residents can call a provincial poison control center symptoms of overdose may include severe drowsiness slowedreduced reflexes slowed breathing loss of consciousness\\\", \\\"tags\\\": \\\"['brain' 'lightheadedness' 'dizziness' 'coldness' 'allergic reaction']\\\"}\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read JSONL file into a list\n",
    "with open(\"formatted_validation_data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Print first few entries\n",
    "for entry in data[:3]:  # Change 3 to any number you want\n",
    "    print(json.dumps(entry, indent=4))  # Pretty-print JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:23.402257Z",
     "iopub.status.busy": "2025-02-10T14:16:23.401949Z",
     "iopub.status.idle": "2025-02-10T14:16:30.015054Z",
     "shell.execute_reply": "2025-02-10T14:16:30.013853Z",
     "shell.execute_reply.started": "2025-02-10T14:16:23.402231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# make sure to use the latest version of the openai python package\n",
    "!pip install --upgrade --quiet openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:30.016813Z",
     "iopub.status.busy": "2025-02-10T14:16:30.016439Z",
     "iopub.status.idle": "2025-02-10T14:16:31.109450Z",
     "shell.execute_reply": "2025-02-10T14:16:31.108559Z",
     "shell.execute_reply.started": "2025-02-10T14:16:30.016781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "your_api_key=\"\"\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key = your_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:31.111884Z",
     "iopub.status.busy": "2025-02-10T14:16:31.111595Z",
     "iopub.status.idle": "2025-02-10T14:16:32.720958Z",
     "shell.execute_reply": "2025-02-10T14:16:32.719931Z",
     "shell.execute_reply.started": "2025-02-10T14:16:31.111859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upload_training_file(file_path):\n",
    "    \"\"\"Upload training file to OpenAI\"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        response = client.files.create(\n",
    "            file=file,\n",
    "            purpose=\"fine-tune\"\n",
    "        )\n",
    "        return response.id\n",
    "\n",
    "# Upload both training and validation files\n",
    "training_file_id = upload_training_file(\"formatted_training_data.jsonl\")\n",
    "validation_file_id = upload_training_file(\"formatted_validation_data.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T14:16:32.722780Z",
     "iopub.status.busy": "2025-02-10T14:16:32.722373Z",
     "iopub.status.idle": "2025-02-10T14:16:34.382833Z",
     "shell.execute_reply": "2025-02-10T14:16:34.381392Z",
     "shell.execute_reply.started": "2025-02-10T14:16:32.722744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7cce1cdf15c9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-0125\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Start the fine-tuning job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fine_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_file_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7cce1cdf15c9>\u001b[0m in \u001b[0;36mcreate_fine_tuning_job\u001b[0;34m(training_file_id, validation_file_id, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_fine_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_file_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-0125\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Create a fine-tuning job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     response = client.fine_tuning.jobs.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_file_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_file_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/fine_tuning/jobs/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, training_file, hyperparameters, integrations, method, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;34m\"/fine_tuning/jobs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
     ]
    }
   ],
   "source": [
    "def create_fine_tuning_job(training_file_id, validation_file_id=None, model=\"gpt-3.5-turbo-0125\"):\n",
    "    \"\"\"Create a fine-tuning job\"\"\"\n",
    "    response = client.fine_tuning.jobs.create(\n",
    "        training_file=training_file_id,\n",
    "        validation_file=validation_file_id,\n",
    "        model=model\n",
    "    )\n",
    "    return response.id\n",
    "model=\"gpt-3.5-turbo-0125\"\n",
    "# Start the fine-tuning job\n",
    "job_id = create_fine_tuning_job(training_file_id, validation_file_id, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-10T14:16:34.383569Z",
     "iopub.status.idle": "2025-02-10T14:16:34.383956Z",
     "shell.execute_reply": "2025-02-10T14:16:34.383784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def monitor_job(job_id):\n",
    "    \"\"\"Monitor fine-tuning job progress\"\"\"\n",
    "    while True:\n",
    "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        print(f\"Status: {job.status}\")\n",
    "\n",
    "        if job.status in [\"succeeded\", \"failed\"]:\n",
    "            return job\n",
    "\n",
    "        # List latest events\n",
    "        events = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job_id,\n",
    "            limit=5\n",
    "        )\n",
    "        for event in events.data:\n",
    "            print(f\"Event: {event.message}\")\n",
    "\n",
    "        sleep(30)  # Check every 30 seconds\n",
    "\n",
    "# Monitor the job until completion\n",
    "job = monitor_job(job_id)\n",
    "if job.status == \"succeeded\":\n",
    "    fine_tuned_model = job.fine_tuned_model\n",
    "    print(f\"Fine-tuned model ID: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-10T14:16:34.384992Z",
     "iopub.status.idle": "2025-02-10T14:16:34.385354Z",
     "shell.execute_reply": "2025-02-10T14:16:34.385229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model_id, test_input):\n",
    "    \"\"\"Test the fine-tuned model\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract Details from medical report\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": test_input}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-10T14:16:34.386256Z",
     "iopub.status.idle": "2025-02-10T14:16:34.386584Z",
     "shell.execute_reply": "2025-02-10T14:16:34.386429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test input\n",
    "test_report = \"\"\"Marcus Wong, a 19-year-old male, presents with severe acne \n",
    "on face and upper back present for 1 year. Multiple inflammatory papules \n",
    "and nodules noted on examination. Previous trials of over-the-counter \n",
    "treatments ineffective. Started on Isotretinoin 40mg daily with monthly \n",
    "liver function monitoring.\"\"\"\n",
    "\n",
    "# Get prediction\n",
    "result = test_model(fine_tuned_model, test_report)\n",
    "\n",
    "# Parse the JSON response\n",
    "import json\n",
    "extracted_data = json.loads(result.content)\n",
    "print(json.dumps(extracted_data, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3431658,
     "sourceId": 5987788,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
